{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37aad532",
   "metadata": {},
   "source": [
    "# Selenium scraper for multiple websites which let you search by ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290dc02",
   "metadata": {},
   "source": [
    "### pip installs libraries.\n",
    "note: %%capture suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bcfc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23460afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f5b32",
   "metadata": {},
   "source": [
    "## Define parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "203e1b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_TO_SEARCH = None #'CO'\n",
    "    # Options include 'CO' and None\n",
    "SITES_TO_SEARCH = ['Rent.']\n",
    "    # Options include 'Realtor' and 'Rent.'\n",
    "\n",
    "WAIT_TIME_DICT = {'CONSTANT':{'Realtor':10,'Rent.':0,'other': 2},\n",
    "                     # whether or not site redirects to CAPTCHA\n",
    "                  'FAILURE' :{'Realtor':25,'Rent.':5,'other':10}\n",
    "                     # after site redirects to CAPTCHA\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7e260",
   "metadata": {},
   "source": [
    "## Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d088c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "    #from webdriver_manager.firefox import GeckoDriverManager\n",
    "import pandas # for reading the txt with ZIPs\n",
    "import datetime # for file names\n",
    "import os # for checking if files exist\n",
    "import bs4 # for knowing how many pages there are per ZIP\n",
    "from time import sleep\n",
    "from tqdm import tqdm # progress bar\n",
    "import requests # for headless version\n",
    "Service = ChromeService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4174495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41070 ZIPs to scrape\n"
     ]
    }
   ],
   "source": [
    "DF = pandas.read_csv(\"sorted_zipmha22.txt\",\n",
    "                     delimiter = \" \", names = [\"ZIP\",\"MHA\"])\n",
    "DF['State'] = DF.apply(lambda row: row['MHA'][:2], axis = 1)\n",
    "if STATE_TO_SEARCH:\n",
    "    assert type(STATE_TO_SEARCH) == str\n",
    "    DF = DF[DF['State'] == STATE_TO_SEARCH]\n",
    "ZIPs = list(DF['ZIP'])\n",
    "ZIPs = [str(ZIP).zfill(5) for ZIP in ZIPs]\n",
    "print(\"There are\",len(ZIPs),\"ZIPs to scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "409e6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ChromeDriverManager().install()\n",
    "#PATH = GeckoDriverManager().install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8a16b",
   "metadata": {},
   "source": [
    "## Define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32804c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WAIT_TIME(context, site):\n",
    "    if site in WAIT_TIME_DICT[context].keys():\n",
    "        return WAIT_TIME_DICT[context][site]\n",
    "    else:\n",
    "        return WAIT_TIME_DICT[context]['other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54da2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /appartments includes houses for rent\n",
    "def URL(site, ZIP, page = 1):\n",
    "    assert type(site) == str\n",
    "    assert type(ZIP ) == str\n",
    "    return {'Realtor':\"https://www.realtor.com/apartments/{}/pg-{}\".format(ZIP, page),\n",
    "            'Rent.'  :\"https://www.rent.com/zip-{}-apartments?page={}\".format(ZIP, page),\n",
    "            #'Zillow' :\"https://www.zillow.com/homes/{}_r/\".format(ZIP),\n",
    "            'trulia' :\"https://www.trulia.com/for_rent/{}_zip/\".format(ZIP),\n",
    "            'REDFIN' :\"https://www.redfin.com/zipcode/{}/apartments-for-rent/page-{}\".format(ZIP, page)\n",
    "           }[site]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09b1db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFilePath(site, ZIP, page = '1'):\n",
    "    for var in [site, ZIP, page]: assert type(var) == str\n",
    "    fileName = page.zfill(2)\n",
    "    if not ('.' in fileName): fileName += '.html'\n",
    "    \n",
    "    filePathParts = ['HTMLs/']\n",
    "\n",
    "    if STATE_TO_SEARCH: # if searching just one state\n",
    "        assert type(STATE_TO_SEARCH) == str\n",
    "        filePathParts.append(STATE_TO_SEARCH + '/')\n",
    "    \n",
    "    filePathParts.append(site.replace('.','') + '/')\n",
    "    \n",
    "    dateString = str(datetime.date.today())\n",
    "    filePathParts.append(dateString + '/')\n",
    "    \n",
    "    filePathParts.append(ZIP + '/')\n",
    "    \n",
    "    filePath = \"\"\n",
    "    for filePathPart in filePathParts:\n",
    "        filePath += filePathPart\n",
    "        if not os.path.exists(filePath): os.mkdir(filePath)\n",
    "    \n",
    "    filePath += fileName\n",
    "    \n",
    "    return filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a4721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HTML_to_file(HTML, filePath):\n",
    "    # Does not check if file already exists.\n",
    "        # Only run if file does not exists or should be written over.\n",
    "    with open(filePath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(HTML)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a8561e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_MIN_SIZE = 100 # KB\n",
    "HTML_MIN_SIZE *= 1000 #KB -> B\n",
    "\n",
    "def isValidHTML(filePath):\n",
    "    if os.path.exists(filePath):\n",
    "        if os.path.getsize(filePath) < HTML_MIN_SIZE:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f794246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseNumPages(site, HTML):\n",
    "    if site == 'Rent.':\n",
    "        PROPS_PER_PAGE = 30\n",
    "        numPropsTags = bs4.BeautifulSoup(HTML).find_all(class_ = \"truncate text-gray-600\")\n",
    "        if len(numPropsTags) >= 1:\n",
    "            numPropsText = numPropsTags[0].text\n",
    "            numPropsText = numPropsText.split(\" \")[0] # take only text before space\n",
    "            numPropsText = numPropsText.replace(',','') # replace commas with nothing\n",
    "            numProps = int(numPropsText)\n",
    "            numPages = 1 + (numProps - 1) // PROPS_PER_PAGE\n",
    "            return numPages\n",
    "        else: return 1        \n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab1cf7",
   "metadata": {},
   "source": [
    "All interacitons with the Selenium Chrome driver are under the getPage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "177fbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPage(URL, headless = False):\n",
    "    if headless:\n",
    "        HTML = requests.get(URL).content\n",
    "        HTML = str(HTML)\n",
    "    else:\n",
    "        global driver\n",
    "        try: driver.get(URL)\n",
    "        except:\n",
    "            print(\"Starting new driver.\")\n",
    "            driver = webdriver.Chrome(service = Service(executable_path = PATH))\n",
    "                #driver = webdriver.Firefox(service = Service(executable_path = PATH))\n",
    "        try: HTML = driver.page_source\n",
    "        except:\n",
    "            return getPage(URL, headless = headless)\n",
    "        if len(HTML) < HTML_MIN_SIZE:\n",
    "            driver.quit()\n",
    "            sleep(WAIT_TIME('FAILURE',site))\n",
    "            driver = webdriver.Chrome(service = Service(executable_path = PATH))\n",
    "    if len(HTML) < HTML_MIN_SIZE:\n",
    "        return getPage(URL, headless = headless)\n",
    "    return HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0afd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadZIP(site, ZIP, headless = False):\n",
    "    filePath = generateFilePath(site, ZIP)\n",
    "    if not isValidHTML(filePath):\n",
    "        HTML = getPage(URL(site, ZIP), headless)\n",
    "        HTML_to_file(HTML, filePath)\n",
    "        \n",
    "        numPages = parseNumPages(site, HTML)\n",
    "        if not (numPages == -1):\n",
    "            if numPages > 1:\n",
    "                for page in range(2,numPages+1):\n",
    "                    page = str(page)\n",
    "                    filePath = generateFilePath(site, ZIP, page = page)\n",
    "                    HTML = getPage(URL(site, ZIP, page), headless)\n",
    "                    HTML_to_file(HTML, filePath)\n",
    "        \n",
    "        sleep(WAIT_TIME('CONSTANT',site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6331e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 611/41070 [07:44<46:03:45,  4.10s/it]"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service = Service(executable_path = PATH))\n",
    "    #driver = webdriver.Firefox(service = Service(executable_path = PATH))\n",
    "while True:\n",
    "    for site in SITES_TO_SEARCH:\n",
    "        for ZIP in tqdm(ZIPs):\n",
    "            downloadZIP(site, ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ed3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5dea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
