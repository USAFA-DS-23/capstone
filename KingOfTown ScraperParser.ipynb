{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77abe1a4",
   "metadata": {},
   "source": [
    "# Selenium scraper for multiple websites which let you search by ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6290dc02",
   "metadata": {},
   "source": [
    "## pip installs libraries.\n",
    "note: %%capture suppresses output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bcfc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23460afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18352678",
   "metadata": {},
   "source": [
    "## Define parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57b37539",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE_TO_SEARCH = None #'CO'\n",
    "    # Options include 'CO' and None, which searches all 50 states.\n",
    "\n",
    "SITES_TO_SEARCH = ['Redfin','Rent']\n",
    "    # Options include 'Rent.' and 'Redfin'\n",
    "SITE_OPTIONS = ['Rent.','Redfin'] # that can be parsed\n",
    "\n",
    "READ_ONLY = False\n",
    "    # When true no data is downloaded\n",
    "\n",
    "PARSE_WHILE_SCRAPING = True\n",
    "SAVE_RAW_HTML = False # not reccomended\n",
    "SAVE_ZIP_CSVs = True # highly reccomended\n",
    "\n",
    "SAVE_BY_WEEK = True\n",
    "    # instead of saving day of scrape\n",
    "\n",
    "STARTING_ZIP = None\n",
    "    # Lets you search country over multiple days.\n",
    "\n",
    "WAIT_TIME_DICT = {'CONSTANT':{'Realtor':10,'Rent.':0,'other': 0},\n",
    "                     # whether or not site redirects to CAPTCHA\n",
    "                  'FAILURE' :{'other':23}\n",
    "                     # after site redirects to CAPTCHA\n",
    "            }\n",
    "\n",
    "ASSUMPTION = {'PRICE':1,\n",
    "              'SQFT':1,\n",
    "              'BEDS':0,\n",
    "              'BATHS':0\n",
    "}\n",
    "    #When price or sqft is range, what do we assume is the value?\n",
    "        # 0 means minimum\n",
    "        # 1 means maximum\n",
    "        # 0.5 would split the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea641a9",
   "metadata": {},
   "source": [
    "## Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d088c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "#data storage\n",
    "import pandas # for reading the txt with ZIPs\n",
    "from datetime import date # for file names\n",
    "import os # for file interactions\n",
    "from bs4 import BeautifulSoup as Soup # for knowing how many pages there are per ZIP\n",
    "from time import sleep\n",
    "from tqdm import tqdm # progress bar\n",
    "import requests # for headless version\n",
    "from numpy import NaN\n",
    "LONG_DASH, LONGER_DASH = '–', '—'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dff40c",
   "metadata": {},
   "source": [
    "### Import ZIPs and MHAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4174495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41070 ZIPs to scrape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZIP</th>\n",
       "      <th>MHA</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00501</td>\n",
       "      <td>NY218</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00544</td>\n",
       "      <td>NY218</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00601</td>\n",
       "      <td>XX499</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00602</td>\n",
       "      <td>XX499</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00603</td>\n",
       "      <td>XX499</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ZIP    MHA State\n",
       "0  00501  NY218    NY\n",
       "1  00544  NY218    NY\n",
       "2  00601  XX499    XX\n",
       "3  00602  XX499    XX\n",
       "4  00603  XX499    XX"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHAs = pandas.read_csv(\"sorted_zipmha22.txt\",\n",
    "                     delimiter = \" \", names = [\"ZIP\",\"MHA\"],\n",
    "                    dtype = {'ZIP':str})\n",
    "MHAs['State'] = MHAs.apply(lambda row: row['MHA'][:2], axis = 1)\n",
    "if STATE_TO_SEARCH:\n",
    "    assert type(STATE_TO_SEARCH) == str\n",
    "    MHAs = MHAs[MHAs['State'] == STATE_TO_SEARCH]\n",
    "ZIPs = list(MHAs['ZIP'])\n",
    "ZIPs = [str(ZIP).zfill(5) for ZIP in ZIPs]\n",
    "if STARTING_ZIP:\n",
    "    startIndex = ZIPs.index(str(STARTING_ZIP))\n",
    "    ZIPs = ZIPs[startIndex:] + ZIPs[:startIndex]\n",
    "print(\"There are\",len(ZIPs),\"ZIPs to scrape\")\n",
    "MHAs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3740b3b9",
   "metadata": {},
   "source": [
    "### Install Selenium Driver Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409e6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = ChromeDriverManager().install()\n",
    "#PATH = GeckoDriverManager().install()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604f090",
   "metadata": {},
   "source": [
    "# Define functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "981ef620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WAIT_TIME(context, site = 'other'):\n",
    "    if site in WAIT_TIME_DICT[context].keys():\n",
    "        return WAIT_TIME_DICT[context][site]\n",
    "    else:\n",
    "        return WAIT_TIME_DICT[context]['other']\n",
    "def wait(context, site = 'other'):\n",
    "    sleep(WAIT_TIME(context, site = site))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e848a1",
   "metadata": {},
   "source": [
    "### Generate URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54da2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /appartments includes houses for rent\n",
    "def URL(site, ZIP, page = 1):\n",
    "    assert type(site) == str\n",
    "    assert type(ZIP ) == str\n",
    "    return {'Realtor':\"https://www.realtor.com/apartments/{}/pg-{}\".format(ZIP, page),\n",
    "            'Rent.'  :\"https://www.rent.com/zip-{}-apartments?page={}\".format(ZIP, page),\n",
    "            #'Zillow' :\"https://www.zillow.com/homes/{}_r/\".format(ZIP),\n",
    "            'trulia' :\"https://www.trulia.com/for_rent/{}_zip/\".format(ZIP),\n",
    "            'Redfin' :\"https://www.redfin.com/zipcode/{}/apartments-for-rent/page-{}\".format(ZIP, page)\n",
    "           }[site]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6065a1",
   "metadata": {},
   "source": [
    "### Create folders and return a file path to write a file to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b1db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES_GET_SEPARATE_FOLDERS = False\n",
    "def makeFilePath(site, ZIP = None, fileType = 'HTML', dateOf = date.today(), page = '1'):\n",
    "    for var in [site, page, fileType]: assert type(var) == str, f\"{var} is not a string\"\n",
    "    assert fileType in ['HTML','ZIP CSV','Compiled CSV','Processed CSV']\n",
    "    filePathParts = ['Scraped_Data']\n",
    "    \n",
    "    if STATES_GET_SEPARATE_FOLDERS:\n",
    "        if STATE_TO_SEARCH: # if searching just one state\n",
    "            assert type(STATE_TO_SEARCH) == str\n",
    "            filePathParts.append(STATE_TO_SEARCH)\n",
    "    \n",
    "    filePathParts.append(fileType+'s') # FILE -> FILEs\n",
    "    \n",
    "    filePathParts.append(site.replace('.',''))\n",
    "    \n",
    "    dateString = str(dateOf.isocalendar()[:2]) if SAVE_BY_WEEK else str(dateOf)\n",
    "    if not 'Compiled' in fileType: filePathParts.append(dateString)\n",
    "\n",
    "    if fileType == 'HTML':\n",
    "        filePathParts.append(ZIP)\n",
    "        fileName = page.zfill(2)\n",
    "        if not ('.' in fileName): fileName += '.html'\n",
    "    elif 'CSV' in fileType:\n",
    "        if 'ZIP' in fileType:\n",
    "            assert type(ZIP) == str\n",
    "            fileName = ZIP\n",
    "        elif 'Compiled' in fileType: fileName = dateString\n",
    "        if not ('.' in fileName): fileName += '.CSV'\n",
    "    \n",
    "    filePath = \"\"\n",
    "    for filePathPart in filePathParts:\n",
    "        filePath = filePath + filePathPart + '/'\n",
    "        if not os.path.exists(filePath): os.mkdir(filePath)\n",
    "    \n",
    "    filePath += fileName\n",
    "    return filePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781b8eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scraped_Data/HTMLs/Test/(2022, 48)/12345/01.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeFilePath('Test','12345', fileType = 'HTML')#'Compiled CSV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a4721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HTML_to_file(HTML, filePath):\n",
    "    # Does not check if file already exists.\n",
    "        # Only run if file does not exists or should be written over.\n",
    "    with open(filePath, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(HTML)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8561e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML_MIN_SIZE = 100 # KB\n",
    "HTML_MIN_SIZE *= 1000 #KB -> B\n",
    "\n",
    "def isValidHTML(filePath):\n",
    "    if os.path.exists(filePath):\n",
    "        if os.path.getsize(filePath) >= HTML_MIN_SIZE:\n",
    "            return True\n",
    "    # else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3835b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRedfinNumPages(pageSoup):\n",
    "    pageSummary = pageSoup.find(class_=\"homes summary\")\n",
    "    if not pageSummary: return 1\n",
    "    pageSummary = pageSummary.text\n",
    "    if not 'of' in pageSummary: return 1\n",
    "    propsPerPage = int(pageSummary.split(' ')[0])\n",
    "    numPropsText = pageSummary.split('of ')[1].split(' ')[0]\n",
    "    numProps = int(numPropsText)\n",
    "    numPages = 1 + (numProps - 1) // propsPerPage\n",
    "    if numPages > 9: numPages = 9\n",
    "    return numPages\n",
    "    \n",
    "def parseRentNumPages(pageSoup):\n",
    "    propsPerPage = 30\n",
    "    numPropsTags = pageSoup.find_all(class_ = \"truncate text-gray-600\")\n",
    "    if len(numPropsTags) <= 0: return 1\n",
    "    numPropsText = numPropsTags[0].text\n",
    "    numPropsText = numPropsText.split(\" \")[0] # take only text before space\n",
    "    numPropsText = numPropsText.replace(',','') # replace commas with nothing\n",
    "    numProps = int(numPropsText)\n",
    "    numPages = 1 + (numProps - 1) // propsPerPage\n",
    "    return numPages\n",
    "\n",
    "def parseNumPages(site, firstPage):\n",
    "    if site not in ['Redfin', 'Rent.']: return -1\n",
    "    pageSoup = Soup(firstPage) if (type(firstPage) == str) else firstPage\n",
    "    return{'Redfin':parseRedfinNumPages,\n",
    "            'Rent.':parseRentNumPages\n",
    "    }[site](pageSoup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af481be",
   "metadata": {},
   "source": [
    "### All interacitons with the Selenium Chrome driver are under the getPage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b27acd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startNewDriver():\n",
    "    global driver\n",
    "    driver = webdriver.Chrome(service = Service(executable_path = PATH))\n",
    "        #driver = webdriver.Firefox(service = Service(executable_path = PATH))\n",
    "    return driver\n",
    "\n",
    "def getPage(URL, headless = False):\n",
    "    if headless:\n",
    "        HTML = requests.get(URL).content\n",
    "        HTML = str(HTML)\n",
    "    else:\n",
    "        global driver\n",
    "        try: driver.get(URL)\n",
    "        except:\n",
    "            print(\"Starting new driver.\")\n",
    "            driver = startNewDriver()\n",
    "                \n",
    "        try: HTML = driver.page_source\n",
    "        except:\n",
    "            return getPage(URL, headless = headless)\n",
    "        if len(HTML) < HTML_MIN_SIZE:\n",
    "            driver.quit()\n",
    "            wait('FAILURE')\n",
    "            driver = startNewDriver()\n",
    "    if len(HTML) < HTML_MIN_SIZE:\n",
    "        return getPage(URL, headless = headless)\n",
    "    return HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b762cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def whichSite(page):\n",
    "    if type(page) == str: page = Soup(page)\n",
    "    for site in SITE_OPTIONS:\n",
    "        if site in page.find(\"title\").text:\n",
    "            return site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c55c2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsePage(page):\n",
    "    pageSoup = Soup(page) if (type(page) == str) else page\n",
    "    site = whichSite(pageSoup)\n",
    "    if site == 'Rent.':\n",
    "        columns = pageSoup.find_all(class_ = \"flex flex-col gap-y-12\")\n",
    "        allCards = []\n",
    "        for column in columns:\n",
    "            someCards = column.find_all(attrs = {'data-tag_section':\"free\"})\n",
    "            allCards.extend(someCards)\n",
    "            someCards = column.find_all(attrs = {'data-tag_section':\"paid\"})\n",
    "            allCards.extend(someCards)\n",
    "        return allCards\n",
    "    elif site == 'Redfin':\n",
    "        allCards = []\n",
    "        for section in pageSoup.find_all(class_=\"HomeCardsContainer flex flex-wrap\"):\n",
    "            allCards.extend(section)\n",
    "        return allCards\n",
    "    else: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de416d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def priceUnavailable(apartment):\n",
    "    for phrase in ['Contact for Price',\n",
    "                  'Price Unavailable']:\n",
    "        if phrase in apartment.text:\n",
    "            return True\n",
    "    return False # <- else\n",
    "\n",
    "def priceAvailable(apartment):\n",
    "    return not priceUnavailable(apartment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e39a5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseOneRentCard(card):\n",
    "    details = card.find_all(\"dd\", class_ = \"font-normal text-body-color\")\n",
    "    hiddenPrice = \"Price Unavailable\"\n",
    "    Sqftage = \"Square Footage Unavailable\"\n",
    "    for detail in details:\n",
    "        if '$' in detail.text:\n",
    "            hiddenPrice = detail.text\n",
    "        if 'Sqft' in detail.text: Sqftage = detail.text\n",
    "    if priceAvailable(card):\n",
    "        shownPrice  = card.find(\"p\", class_ = \"flex flex-1 items-center text-lg font-semibold text-black\").text\n",
    "        if LONG_DASH in hiddenPrice: price = hiddenPrice # price range\n",
    "        else: price = shownPrice # shown price sometimes includes +\n",
    "    else:\n",
    "        price = \"Price Unavailable\"\n",
    "    if 'Units Available' in card.text:\n",
    "        card.find(attrs = {\"data-tid\":\"available-units\"}).text.strip().split(' ')[0]\n",
    "        \n",
    "    cardData = {\n",
    "        'address':card.find_all(class_=\"overflow-hidden overflow-ellipsis whitespace-nowrap font-normal text-body-color\")[0].text,\n",
    "        'beds-baths':card.find_all(attrs = {'data-tid':\"beds-baths\"})[0].text,\n",
    "        'price':price, 'square footage':Sqftage\n",
    "    }\n",
    "    return cardData\n",
    "\n",
    "def parseOneRedfinCard(card):\n",
    "    price = 'Price Unavailable'\n",
    "    if priceAvailable(card):\n",
    "        price = card.find('span', class_=\"homecardV2Price\")\n",
    "        if price:\n",
    "            price = price.text\n",
    "    \n",
    "    beds  = 'Beds Unavailable'\n",
    "    baths = 'Baths Unavailable'\n",
    "    SqFt  = 'Square Footage Unavailable'\n",
    "    stats = card.find_all(\"div\", class_=\"stats\")\n",
    "    if card.find(class_=\"VerifiedBadge includeLabel margin-left-smaller padding-top-small\"): verified = 'verified'\n",
    "    else: verified = 'not verified'\n",
    "    for statSoup in stats:\n",
    "        stat = statSoup.text\n",
    "        if 'Bed'     in stat: beds  = stat\n",
    "        if 'Bath'    in stat: baths = stat\n",
    "        if 'Sq. Ft.' in stat: SqFt  = stat\n",
    "    try: homeType = card.find(class_=\"PropertyTypeDisplay font-size-smaller padding-top-small\").find(\"span\").text[1:]\n",
    "    except: homeType = \"Type Unknown\"\n",
    "    cardData = {\n",
    "        'address':card.find(class_=\"homeAddressV2\").text,\n",
    "        'beds':beds, 'baths':baths, 'type':homeType,\n",
    "        'price':price, 'square footage':SqFt, 'verified':verified\n",
    "    }\n",
    "    return cardData\n",
    "def parseOneCard(site, card):\n",
    "    return{'Rent.':parseOneRentCard,\n",
    "          'Redfin':parseOneRedfinCard}[site](card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c17522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidRentApartment(card):\n",
    "    bed_baths = card.find_all(attrs = {'data-tid':\"beds-baths\"})\n",
    "    if bed_baths: return True\n",
    "    else: return False\n",
    "def isValidRedfinApartment(card):\n",
    "    if card.find(class_=\"homeAddressV2\"):\n",
    "        return True\n",
    "    else: return False\n",
    "def isValidApartment(site, card):\n",
    "    return{'Rent.':isValidRentApartment,\n",
    "          'Redfin':isValidRedfinApartment}[site](card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "376a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseRentCards(cards):\n",
    "    parseCards('Rent.',cards)\n",
    "def parseRedfinCards(cards):\n",
    "    parseCards('Redfin',cards)\n",
    "def parseCards(site, cards):\n",
    "    apartmentData = []\n",
    "    for card in cards:\n",
    "        if isValidApartment(site, card):\n",
    "            apartmentData.append(parseOneCard(site, card))\n",
    "    #return apartmentData\n",
    "    return pandas.json_normalize(apartmentData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0afd39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handlePage(site, ZIP, HTML, pageSoup = None, page = '1'):\n",
    "    if not pageSoup: pageSoup = Soup(HTML)\n",
    "    if SAVE_RAW_HTML:\n",
    "        filePath = makeFilePath(site, ZIP, page = page, fileType = 'HTML')\n",
    "        HTML_to_file(HTML, filePath)\n",
    "    if PARSE_WHILE_SCRAPING: return parseCards(site, parsePage(pageSoup))\n",
    "\n",
    "def downloadZIP(site, ZIP, headless = False):\n",
    "    if READ_ONLY: return pandas.DataFrame()\n",
    "    # fixme doesn't work for Rent. for some reason\n",
    "    # Page 1\n",
    "    HTML = getPage(URL(site, ZIP), headless)\n",
    "    pageSoup = Soup(HTML)\n",
    "    \n",
    "    DFs = [handlePage(site, ZIP, HTML, pageSoup = pageSoup)]\n",
    "\n",
    "    numPages = parseNumPages(site, pageSoup)\n",
    "    if not (numPages == -1):\n",
    "        if numPages > 1:\n",
    "            for page in range(2,numPages+1):\n",
    "                # For pages after page 1\n",
    "                page = str(page)\n",
    "                HTML = getPage(URL(site, ZIP, page), headless)\n",
    "                DF = handlePage(site, ZIP, HTML, page = page)\n",
    "                DFs.append(DF)\n",
    "\n",
    "    wait('CONSTANT',site = site)\n",
    "    if PARSE_WHILE_SCRAPING:\n",
    "        DF = pandas.concat(DFs)\n",
    "        if SAVE_ZIP_CSVs:\n",
    "            filePath = makeFilePath(site, ZIP, fileType = 'ZIP CSV')\n",
    "            DF.to_csv(filePath, index = False)\n",
    "        return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f71fd92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downloadZIP('Redfin','16801')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee1477b",
   "metadata": {},
   "source": [
    "# Download and save everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7328d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pre-compiled CSV\n"
     ]
    }
   ],
   "source": [
    "def getZIP(site, ZIP):\n",
    "    filePath = makeFilePath(site, ZIP = ZIP, fileType = 'ZIP CSV')\n",
    "    if os.path.exists(filePath):\n",
    "        try:\n",
    "            DF = pandas.read_csv(filePath)\n",
    "        except:\n",
    "            os.remove(filePath)\n",
    "            DF = downloadZIP(site, ZIP)\n",
    "    else:\n",
    "        # assume HTML was not downloaded and make no attempt to find it # fixme\n",
    "        DF = downloadZIP(site, ZIP)\n",
    "    DFs.append(DF)\n",
    "\n",
    "if not READ_ONLY: driver = startNewDriver()\n",
    "masterDFs = {}\n",
    "for site in SITES_TO_SEARCH:\n",
    "    compiledFilePath = makeFilePath(site, fileType = 'Compiled CSV')\n",
    "    if os.path.exists(compiledFilePath):\n",
    "        print(\"Reading pre-compiled CSV\")\n",
    "        masterDF = pandas.read_csv(compiledFilePath)\n",
    "    else: # no pre-existing compiled data\n",
    "        DFs = [] # each DF will represent one ZIP\n",
    "        for ZIP in tqdm(ZIPs):\n",
    "            DF = getZIP(site, ZIP)\n",
    "            DFs.append(DF)\n",
    "        masterDF = pandas.concat(DFs, axis = 0)\n",
    "        masterDF.to_csv(compiledFilePath)\n",
    "    masterDFs[site] = masterDF\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c7f2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145773\n"
     ]
    }
   ],
   "source": [
    "for masterDF in masterDFs.values():\n",
    "    print(len(masterDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "778eaa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = masterDFs['Redfin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c230a",
   "metadata": {},
   "source": [
    "# Derive numbers from text in DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcd20c",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93aa729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStudio(string):\n",
    "    return string.replace('Studio–','')\n",
    "def getBeds(row):\n",
    "    return parseBedsBaths(row, 'beds')\n",
    "def getBaths(row):\n",
    "    return parseBedsBaths(row, 'baths')\n",
    "def parseBedsBaths(row, output):\n",
    "    assert output in ['beds', 'baths']\n",
    "    string = row['beds-baths']\n",
    "    string = removeStudio(string)\n",
    "    if output == 'beds':\n",
    "        if 'Bed' in string: return string.split('Bed')[0].strip()\n",
    "        else: return('Beds Unknown')\n",
    "    elif output == 'baths':\n",
    "        if 'Bath' in string: return string.split('Bath')[0].split('•')[1].strip()\n",
    "        else: return('Baths Unknown')\n",
    "def getZIP(row):\n",
    "    address = row['address']\n",
    "    if type(address) == float: return NaN\n",
    "    return address.split(' ')[-1]\n",
    "\n",
    "for key in ['PRICE','SQFT']: assert ((ASSUMPTION[key] >= 0) and (ASSUMPTION[key] <= 1))\n",
    "def parseRange(string, key):\n",
    "    if not string: return NaN\n",
    "    if type(string) == float: return string\n",
    "    if ('Unavailable' in string) or (LONGER_DASH in string): return NaN\n",
    "    for subString in [',', '$', '+', ' Sqft', '/mo', ' Sq. Ft.']:\n",
    "        string = string.replace(subString, '')\n",
    "    for dash in ['-', LONG_DASH]:\n",
    "        if (dash in string):\n",
    "            [minStr,maxStr] = string.split(dash)\n",
    "            minVal = int(minStr)\n",
    "            maxVal = int(maxStr)\n",
    "            valRange = maxVal - minVal\n",
    "            return minVal + valRange*ASSUMPTION[key]\n",
    "    #else\n",
    "    return int(string)\n",
    "\n",
    "def getPrice(row): return parseRange(row['price'],          'PRICE')\n",
    "def getSqft (row): return parseRange(row['square footage'], 'SQFT' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416f0f5",
   "metadata": {},
   "source": [
    "### apply to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "77c9869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no column to parse\n"
     ]
    }
   ],
   "source": [
    "if 'beds-baths' in DF.columns:\n",
    "    DF['beds'] = DF.apply(getBeds, axis = 1)\n",
    "    DF['baths'] = DF.apply(getBaths, axis = 1)\n",
    "    DF.pop('beds-baths')\n",
    "    print(\"beds-baths column split\")\n",
    "else:\n",
    "    print(\"no column to parse\")\n",
    "\n",
    "DF['price as number'] = DF.apply(getPrice, axis = 1)\n",
    "DF['ZIP'] = DF.apply(getZIP, axis = 1)\n",
    "DF['sqft as number'] = DF.apply(getSqft, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c696c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.merge(MHAs, on = ['ZIP'], how = 'inner').sort_values('ZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4881d47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'address', 'beds', 'baths', 'type',\n",
       "       'price', 'square footage', 'verified', 'price as number', 'ZIP',\n",
       "       'sqft as number', 'MHA', 'State'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d17bf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>price as number</th>\n",
       "      <th>sqft as number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHA</th>\n",
       "      <th>beds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, Unnamed: 0, price as number, sqft as number]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.where(DF['ZIP'] == '16801').dropna().groupby(['MHA','beds']).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b312ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>type</th>\n",
       "      <th>price</th>\n",
       "      <th>square footage</th>\n",
       "      <th>verified</th>\n",
       "      <th>price as number</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>sqft as number</th>\n",
       "      <th>MHA</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.1, Unnamed: 0, address, beds, baths, type, price, square footage, verified, price as number, ZIP, sqft as number, MHA, State]\n",
       "Index: []"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.where(DF['ZIP'] == '16801').dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
